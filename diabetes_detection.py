# -*- coding: utf-8 -*-
"""Diabetes Detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rHR5UFX2FVyIPE0eA7E68EWQc4sgNUtC
"""

import tensorflow as tf
import numpy as np
import pandas as pd
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.python.keras.engine.training import Model

from google.colab import drive
drive.mount('/content/drive')

file_url = "/content/drive/MyDrive/diabetes.csv"
dataframe = pd.read_csv(file_url)

from google.colab import drive
drive.mount('/content/drive')

dataframe.shape
dataframe.head()

dataframe.dtypes

# Commented out IPython magic to ensure Python compatibility.
val_dataframe = dataframe.sample(frac=0.2, random_state=1337)
train_dataframe = dataframe.drop(val_dataframe.index)

print(
    "Using %d samples for training and %d for validation"
#     % (len(train_dataframe), len(val_dataframe))
)

def dataframe_to_dataset(dataframe):
    dataframe = dataframe.copy()
    labels = dataframe.pop("Outcome")
    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))
    ds = ds.shuffle(buffer_size=len(dataframe))
    return ds


train_ds = dataframe_to_dataset(train_dataframe)
val_ds = dataframe_to_dataset(val_dataframe)

for x, y in train_ds.take(1):
    print("Input:", x)
    print("Target:", y)

train_ds = train_ds.batch(32)
val_ds = val_ds.batch(32)

from tensorflow.keras.layers.experimental.preprocessing import Normalization
from tensorflow.keras.layers.experimental.preprocessing import CategoryEncoding
from tensorflow.keras.layers.experimental.preprocessing import StringLookup


def encode_numerical_feature(feature, name, dataset):
    
    normalizer = Normalization()

    feature_ds = dataset.map(lambda x, y: x[name])
    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))

    normalizer.adapt(feature_ds)

    encoded_feature = normalizer(feature)
    return encoded_feature


def encode_string_categorical_feature(feature, name, dataset):
    
    index = StringLookup()

    feature_ds = dataset.map(lambda x, y: x[name])
    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))

    index.adapt(feature_ds)

    encoded_feature = index(feature)

    encoder = CategoryEncoding(output_mode="binary")

    feature_ds = feature_ds.map(index)

    encoder.adapt(feature_ds)

    encoded_feature = encoder(encoded_feature)
    return encoded_feature


def encode_integer_categorical_feature(feature, name, dataset):
    
    encoder = CategoryEncoding(output_mode="binary")

    feature_ds = dataset.map(lambda x, y: x[name])
    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))

    encoder.adapt(feature_ds)

    encoded_feature = encoder(feature)
    return encoded_feature

fa = keras.Input(shape=(1,), name="Pregnancies")
va = keras.Input(shape=(1,), name="Glucose")
ca = keras.Input(shape=(1,), name="BloodPressure")
rs = keras.Input(shape=(1,), name="SkinThickness")
ch = keras.Input(shape=(1,), name="Insulin")
fsd = keras.Input(shape=(1,), name="BMI")
tsd = keras.Input(shape=(1,), name="DiabetesPedigreeFunction")
den = keras.Input(shape=(1,), name="Age")

all_inputs = [
    fa,
    va,
    ca,
    rs,
    ch,
    fsd,
    tsd,
    den,

]


fa_encoded = encode_numerical_feature(fa, "Pregnancies", train_ds)
va_encoded = encode_numerical_feature(va, "Glucose", train_ds)
ca_encoded = encode_numerical_feature(ca, "BloodPressure", train_ds)
rs_encoded = encode_numerical_feature(rs, "SkinThickness", train_ds)
ch_encoded = encode_numerical_feature(ch, "Insulin", train_ds)
fsd_encoded = encode_numerical_feature(fsd, "BMI", train_ds)
tsd_encoded = encode_numerical_feature(tsd, "DiabetesPedigreeFunction", train_ds)
den_encoded = encode_numerical_feature(den, "Age", train_ds)

all_features = layers.concatenate(
    [
        fa_encoded,
        va_encoded,
        ca_encoded,
        rs_encoded,
        ch_encoded,
        fsd_encoded,
        tsd_encoded,
        den_encoded,
        
    ]
)

x = layers.Dense(32, activation="relu")(all_features)
x = layers.Dropout(0.5)(x)
output = layers.Dense(1, activation="sigmoid")(x)
model = keras.Model(all_inputs, output)
model.compile("adam", "binary_crossentropy", metrics=["accuracy"])

model.summary()

keras.utils.plot_model(model, show_shapes=True, rankdir="LR")

h=model.fit(train_ds, epochs=100, validation_data=val_ds)

model.evaluate(val_ds)

import matplotlib.pyplot as plt
plt.title("Accuracy")
plt.plot(h.history['accuracy'])
plt.plot(h.history['val_accuracy'])
plt.xlabel('Epoch')
plt.ylabel("Accuracy")
plt.legend(['accuracy','val_accuracy'],loc='lower right')
plt.show()


plt.title("Loss")
plt.plot(h.history['loss'])
plt.plot(h.history['val_loss'])
plt.xlabel('Epoch')
plt.ylabel("Loss")
plt.legend(['loss','val_loss'],loc='best')
plt.show()

sample = {
    "Pregnancies": 2,
    "Glucose": 140,
    "BloodPressure": 82,
    "SkinThickness": 37,
    "Insulin": 0,
    "BMI": 25.6,
    "DiabetesPedigreeFunction": 0.721,
    "Age": 30,
    
}

input_dict = {name: tf.convert_to_tensor([value]) for name, value in sample.items()}
predictions = model.predict(input_dict)

print(
    "This particular patient had a %.1f percent probability "
    "of having diabetes, as evaluated by our model." % (100 * predictions[0][0],)
)

i=0
predictions = model.predict(val_ds)
predictions.shape=(154,)
for i in range(154):
  if predictions[i]>0.5:
    predictions[i]=1
  else:
    predictions[i]=0

print(predictions)

from sklearn import metrics

print(metrics.accuracy_score(val_dataframe['Outcome'], predictions))

from sklearn import metrics
from sklearn.metrics import plot_confusion_matrix
import seaborn as sn
confusion_matrix = metrics.confusion_matrix(val_dataframe['Outcome'], predictions)
#confusion_matrix

df_cm = pd.DataFrame(confusion_matrix, range(2), range(2))
plt.figure(figsize=(10,7))
sn.set(font_scale=1.4) # for label size
sn.heatmap(df_cm, annot=True, annot_kws={"size": 16}) # font size
plt.show()

tflite_model_name = 'sine_model'  
c_model_name = 'sine_model'
# Convert Keras model to a tflite model
converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]
tflite_model = converter.convert()

open(tflite_model_name + '.tflite', 'wb').write(tflite_model)

# Function: Convert some hex value into an array for C programming
def hex_to_c_array(hex_data, var_name):

  c_str = ''

  # Create header guard
  c_str += '#ifndef ' + var_name.upper() + '_H\n'
  c_str += '#define ' + var_name.upper() + '_H\n\n'

  # Add array length at top of file
  c_str += '\nunsigned int ' + var_name + '_len = ' + str(len(hex_data)) + ';\n'

  # Declare C variable
  c_str += 'unsigned char ' + var_name + '[] = {'
  hex_array = []
  for i, val in enumerate(hex_data) :

    # Construct string from hex
    hex_str = format(val, '#04x')

    # Add formatting so each line stays within 80 characters
    if (i + 1) < len(hex_data):
      hex_str += ','
    if (i + 1) % 12 == 0:
      hex_str += '\n '
    hex_array.append(hex_str)

  # Add closing brace
  c_str += '\n ' + format(' '.join(hex_array)) + '\n};\n\n'

  # Close out header guard
  c_str += '#endif //' + var_name.upper() + '_H'

  return c_str

# Write TFLite model to a C source (or header) file
with open(c_model_name + '.h', 'w') as file:
  file.write(hex_to_c_array(tflite_model, c_model_name))